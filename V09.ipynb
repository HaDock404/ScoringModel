{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda460fe",
   "metadata": {},
   "source": [
    "# Introduction: Home Credit Default Risk Competition\n",
    "Dans ce Notebook, nous participerons au concours de Machine Learning sur le risque de défaut de crédit immobilier actuellement hébergé sur Kaggle. L'objectif de ce concours est d'utiliser les données historiques des demandes de prêt pour prédire si un demandeur sera ou non en mesure de rembourser un prêt. Il s’agit d’une tâche de classification supervisée standard :\n",
    "\n",
    "* __Supervisé__ : les étiquettes sont incluses dans les données d'entraînement et le but est de former un modèle pour apprendre à prédire les étiquettes à partir des fonctionnalités\n",
    "* __Classification__ : Le label est une variable binaire, 0 (remboursera le prêt à temps), 1 (aura des difficultés à rembourser le prêt)\n",
    "\n",
    "# Data\n",
    "Les données sont fournies par [Home Credit](http://www.homecredit.net/about-us.aspx), un service dédié aux lignes de crédit (prêts) fournies à la population non bancarisée. Prédire si un client remboursera ou non un prêt ou aura des difficultés est un besoin commercial essentiel, et Home Credit organise ce concours sur Kaggle pour voir quels types de modèles la communauté d'apprentissage automatique peut développer pour les aider dans cette tâche.\n",
    "\n",
    "Il existe 7 sources de données différentes :\n",
    "\n",
    "* application_train/application_test : les principales données de formation et de test avec des informations sur chaque demande de prêt chez Home Credit. Chaque prêt a sa propre ligne et est identifié par la fonctionnalité « SK_ID_CURR ». Les données de la demande de formation sont accompagnées du 'TARGET' indiquant 0 : le prêt a été remboursé ou 1 : le prêt n'a pas été remboursé.\n",
    "* bureau : données concernant les crédits antérieurs du client auprès d'autres institutions financières. Chaque crédit précédent possède sa propre ligne dans le bureau, mais un prêt dans les données de candidature peut avoir plusieurs crédits précédents.\n",
    "* bureau_balance : données mensuelles sur les crédits précédents en bureau. Chaque ligne représente un mois d'un crédit précédent, et un seul crédit précédent peut avoir plusieurs lignes, une pour chaque mois de la durée du crédit.\n",
    "* previous_application : demandes précédentes de prêts chez Home Credit des clients qui ont des prêts dans les données de la demande. Chaque prêt en cours dans les données de la demande peut avoir plusieurs prêts précédents. Chaque application précédente comporte une ligne et est identifiée par la fonctionnalité « SK_ID_PREV ».\n",
    "* POS_CASH_BALANCE : données mensuelles sur les précédents points de vente ou prêts de trésorerie que les clients ont contractés avec Home Credit. Chaque ligne correspond à un mois d'un point de vente ou d'un prêt de trésorerie précédent, et un seul prêt précédent peut comporter plusieurs lignes.\n",
    "* credit_card_balance : données mensuelles sur les cartes de crédit précédentes que les clients ont eues avec Home Credit. Chaque ligne représente un mois du solde d’une carte de crédit, et une seule carte de crédit peut comporter plusieurs lignes.\n",
    "* installments_payment : historique des paiements des prêts précédents chez Home Credit. Il y a une ligne pour chaque paiement effectué et une ligne pour chaque paiement manqué.\n",
    "\n",
    "## Metric: ROC AUC\n",
    "\n",
    "Une fois que nous avons une compréhension des données (la lecture des [descriptions des colonnes](https://www.kaggle.com/c/home-credit-default-risk/data) aide énormément), nous devons comprendre la métrique en laquelle notre soumission est jugée. Dans ce cas, il s'agit d'une métrique de classification courante connue sous le nom de [Zone caractéristique de fonctionnement du récepteur sous la courbe (ROC AUC, également parfois appelée AUROC)](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it).\n",
    "\n",
    "La [courbe des caractéristiques de fonctionnement du récepteur (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) représente graphiquement le taux de vrais positifs par rapport au taux de faux positifs.\n",
    "\n",
    "L' [Area Under the Curve (AUC)](http://gim.unmc.edu/dxtests/roc3.htm) s'explique par son nom ! Il s'agit simplement de l'aire sous la courbe ROC. (Il s'agit de l'intégrale de la courbe.) Cette métrique est comprise entre 0 et 1, un meilleur modèle ayant un score plus élevé. Un modèle qui devine simplement au hasard aura une ROC AUC de 0,5.\n",
    "\n",
    "Lorsque nous mesurons un classificateur selon le ROC AUC, nous ne générons pas de prédictions 0 ou 1, mais plutôt une probabilité comprise entre 0 et 1. Cela peut prêter à confusion car nous aimons généralement penser en termes de précision, mais lorsque nous rencontrons des problèmes avec des classes déséquilibrées (nous verrons que c'est le cas), la précision n'est pas la meilleure mesure. Par exemple, si je voulais construire un modèle capable de détecter les terroristes avec une précision de 99,9999 %, je créerais simplement un modèle qui prédirait que chaque personne n'est pas un terroriste. Clairement, cela ne serait pas efficace (le rappel serait nul) et nous utilisons des métriques plus avancées telles que le ROC AUC ou le [score F1](https://en.wikipedia.org/wiki/F1_score) pour refléter plus précisément le performances d'un classificateur. Un modèle avec une AUC ROC élevée aura également une grande précision, mais [l'AUC ROC est une meilleure représentation des performances du modèle.](https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy)\n",
    "\n",
    "Commençons à explorer les données. Dans ce notebook, comme mentionné précédemment, nous nous en tiendrons aux principales sources de données et aux modèles simples sur lesquels nous pourrons nous appuyer dans nos travaux futurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ac36a",
   "metadata": {},
   "source": [
    "## Import\n",
    "Nous utiliserons une stack de Data Science habituelle : `numpy`, `pandas`, `sklearn`, `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d66695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
