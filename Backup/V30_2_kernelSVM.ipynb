{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed1007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.svm import SVC  # pour la classification, ou SVR pour la régression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80808e0f",
   "metadata": {},
   "source": [
    "Pour analyser la pertinence du modèle que nous sélectionnerons, nous devons créer une fonction qui pénalise les mauvaises prédiction et plus particulièrement les False Negative. Ce sont des prédictions du modèle qui prédise un 0 alors que nous attendons un 1. Cette prédiction est plus dangereuse pour la pertinence du modèle car si nous prédisons un remboursement probable d'un crédit et que cela n'est pas le cas, cela impacte directement la rentabilité de la banque, ce qui n'est pas souhaitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ee4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_penalty(y_test, y_pred):\n",
    "    y_test = y_test.to_numpy().flatten()\n",
    "    penalty = 0.0\n",
    "    sum_penalty = 0\n",
    "    \n",
    "    for yt, yp in zip(y_test, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            penalty = penalty + 10\n",
    "            sum_penalty = sum_penalty +1\n",
    "        elif yt == 0 and yp == 1:\n",
    "            penalty = penalty + 1\n",
    "            sum_penalty = sum_penalty +1\n",
    "            \n",
    "    score = (penalty/len(y_test))*0.1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d232aff",
   "metadata": {},
   "source": [
    "## SVM à noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06dbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hybrid = pd.read_csv('X_train_CSV_hybrid.csv')\n",
    "X_test_hybrid = pd.read_csv('X_test_CSV_hybrid.csv')\n",
    "y_train_hybrid = pd.read_csv('y_train_CSV_hybrid.csv')\n",
    "y_test_hybrid = pd.read_csv('y_test_CSV_hybrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73317cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_hybrid)\n",
    "X_test_scaled = scaler.transform(X_test_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00639db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68efec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée: [-0.29375  -0.319375 -0.32     -0.3075   -0.31    ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_model, X_train_scaled, y_train_hybrid, cv=5,\\\n",
    "                         scoring='neg_mean_squared_error')\n",
    "print(\"Scores de validation croisée:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab83e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps de traitement est de : 5.990594148635864 secondes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svm_model.fit(X_train_scaled, y_train_hybrid)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Le temps de traitement est de : {execution_time} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc36a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hybrid = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de1d0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.223"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_penalty(y_test_hybrid, y_pred_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebc31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"RMSE : %.2f\" % np.sqrt(metrics.mean_squared_error(y_test_hybrid, y_pred_hybrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ac3e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639367816091954"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_hybrid, y_pred_hybrid)\n",
    "auc_score_hybrid = roc_auc_score(y_test_hybrid, y_pred_hybrid)\n",
    "auc_score_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548d47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under = pd.read_csv('X_train_CSV_under.csv')\n",
    "X_test_under = pd.read_csv('X_test_CSV_under.csv')\n",
    "y_train_under = pd.read_csv('y_train_CSV_under.csv')\n",
    "y_test_under = pd.read_csv('y_test_CSV_under.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265ebb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_under)\n",
    "X_test_scaled = scaler.transform(X_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1792f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe5ba2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée: [-0.42125 -0.42375 -0.42625 -0.43    -0.42625]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_model, X_train_scaled, y_train_hybrid, cv=5,\\\n",
    "                         scoring='neg_mean_squared_error')\n",
    "print(\"Scores de validation croisée:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fce894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps de traitement est de : 5.683660984039307 secondes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svm_model.fit(X_train_scaled, y_train_under)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Le temps de traitement est de : {execution_time} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c6525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_under = svm_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08152486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17775000000000002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_penalty(y_test_under, y_pred_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38afc7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"RMSE : %.2f\" % np.sqrt(metrics.mean_squared_error(y_test_under, y_pred_under)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948c5c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757193663110248"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_under, y_pred_under)\n",
    "auc_score_under = roc_auc_score(y_test_under, y_pred_under)\n",
    "auc_score_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453052a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
